{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_part_class.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-22 -44 -44 -44 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62\n",
      " -62 -63 -63 -63 -63  51  51  51  52  83  83  83  83  83  84  84  84  84\n",
      "  84  84  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91]\n",
      "[   23    23    23    23    23    21    21    21    21    21    21    21\n",
      "    21    21    21    21    21    21    21  2103  2101     2     2    22\n",
      "   -11    22    11   321  2112 -2212  -211   211  -321   211   321   211\n",
      "  -211   321  2212   211  -211   211  -211   211   321  -211   130  -321\n",
      "   211   211  -211  -211  -211   211  -211   211   130   130    22    22\n",
      "    22    22   211  -211    22    22    22    22    22    22    22    22\n",
      "    22    22    22    22    22    22  2112  -211   211  -211    22    22\n",
      "    22    22    22    22    22    22    22    22    22    22   211  -211\n",
      "    22    22    22    22    22    22    22    22   211  -211   211  -211\n",
      "   211  -211    22    22    22    22    22    22]\n",
      "-62\n",
      "[-22 -44 -44 -44 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62 -62\n",
      " -62 -63 -63 -63 -63  51  51  51  52  83  83  83  83  83  84  84  84  84\n",
      "  84  84  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91  91  91]\n"
     ]
    }
   ],
   "source": [
    "print(gen_status[1])\n",
    "print(gen_id[1])\n",
    "\n",
    "print(gen_status[0][5])\n",
    "\n",
    "# for i in range(0,len(gen_status)):\n",
    "#     for j in range(0,len(gen_status[i])):\n",
    "#         if j != 91:\n",
    "#             np.delete(gen_status[i], j)\n",
    "# for i in range(0,4):\n",
    "#     for j in range(0,len(gen_status[i])):\n",
    "#         if j != 91:\n",
    "#             print(np.delete(gen_status[i], j))\n",
    "# x = np.arange(10)\n",
    "# condlist = [x<3, x>5]\n",
    "# choicelist = [x, x**2]\n",
    "# np.select(condlist, choicelist)\n",
    "# for i in range(0,4):\n",
    "#     for j in range(0,len(gen_status[i])):\n",
    "#         condlist = [gen_status[i][j] == 91]\n",
    "#         choicelist = [gen_status[i][j]]\n",
    "#         print(np.select(condlist, choicelist))\n",
    "print(gen_status[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "91\n",
      "[[-22 -44 -44 ... 91 91 91] [-22 -44 -44 ... 91 91 91] [-22 -44 -44 ... 91 91 91] ... [-22 -44 -44 ... 91 91 91] [-22 -44 -44 ... 91 91 91] [-22 -44 -44 ... 91 91 91]]\n"
     ]
    }
   ],
   "source": [
    "# # arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "# # print(arr)\n",
    "# # print(np.delete(arr, 1, 0))\n",
    "\n",
    "# a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "# # index = [2]\n",
    "\n",
    "# # new_a = np.delete(a, index)\n",
    "\n",
    "# # print(new_a.pop(4)) #Prints `[1, 2, 5, 6, 8, 9]\n",
    "# import numpy.ma as ma\n",
    "# # mx = ma.masked_array(a, mask = ((a < 3 ) | (a > 7)) )\n",
    "# # print(mx)\n",
    "\n",
    "# for i in range(0,4):\n",
    "#     mx = ma.masked_array(gen_staus[i], mask = ( gen_status[i] == 91 )\n",
    "\n",
    "# print(mx)\n",
    "for i in range(0,4):\n",
    "    for j in range(0,len(gen_status[i])):\n",
    "        if gen_status[i][j] == 91:\n",
    "#             gen_status[i][j] = np.array(gen_status[i][j])\n",
    "            print(gen_status[i][j])\n",
    "print(gen_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n"
     ]
    }
   ],
   "source": [
    "is_final = abs(gen_status) == 91\n",
    "final_particles = particles[is_final]\n",
    "# for event in range(0,len(gen_id)):\n",
    "#     for part in range(0,len(gen_id[event])):\n",
    "#         if gen_status.any == 91:\n",
    "#             print(gen_id[part])\n",
    "\n",
    "print(len(final_particles[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still need to figure out how to select final state (91) only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#id_bins = np.linspace(0,2000,2001)\n",
    "id_bins = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,21,22,23,24,25,30]\n",
    "plt.hist(x=gen_id.flatten(), bins=id_bins, log=True, density=True)\n",
    "\n",
    "# print(pairings_added.mass.flatten())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z_ee_jet', '...']\n",
      "[0 0 0 ... 0 0 0]\n",
      "2574\n",
      "(2574,)\n",
      "2574\n",
      "(2574,)\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Z_ee_jet', '...']\n",
    "print(class_names)\n",
    "Z_ee_jet = np.array([0]*len(gen_id))\n",
    "print(Z_ee_jet)\n",
    "print(len(Z_ee_jet))\n",
    "print(Z_ee_jet.shape)\n",
    "print(len(gen_id))\n",
    "print(gen_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "\n",
    "# model.add(keras.layers.Embedding(10000, 16))\n",
    "# model.add(keras.layers.GlobalAveragePooling1D())\n",
    "# model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "# model.add(keras.layers.Dense(1, activation=tf.nn.softmax))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(gen_id, Z_ee_jet, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          41200     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 41,489\n",
      "Trainable params: 41,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "part_size = len(gen_id)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(part_size+1, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "# model.add(keras.layers.Dense(1, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['acc'])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(gen_id[0])\n",
    "# print(len(gen_id))\n",
    "# print(len(gen_id)/2)\n",
    "\n",
    "# half = int(len(gen_id)/2)\n",
    "\n",
    "# x_val = gen_id[:half]\n",
    "# partial_x_train = gen_id[half:]\n",
    "\n",
    "# y_val = gen_id[:half]\n",
    "# partial_y_train = gen_id[half:]\n",
    "\n",
    "# print(x_val)\n",
    "# print(partial_x_train)\n",
    "# print(len(x_val))\n",
    "# print(len(partial_x_train))\n",
    "# print(len(gen_id[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574\n",
      "2574\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(len(gen_id)))\n",
    "print(len(gen_id))\n",
    "sizes = []\n",
    "for i in range(0,len(gen_id)):\n",
    "    sizes.append(len(gen_id[i]))\n",
    "print(np.amax(sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Largest size is 1318 elements...so padd up 10 1320 ?**\n",
    "\n",
    "**For now...haven't cut down to include only final stat yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_id = keras.preprocessing.sequence.pad_sequences(gen_id,\n",
    "                                                    value=0,\n",
    "                                                    padding='post',\n",
    "                                                    maxlen=1320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574\n",
      "1287.0\n",
      "[[23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " ...\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]]\n",
      "[[23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " ...\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]\n",
      " [23 23 23 ...  0  0  0]]\n",
      "1287\n",
      "1287\n",
      "1320\n",
      "1320\n",
      "1320\n",
      "(1287, 1320)\n",
      "(1287, 1320)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "(1287,)\n",
      "(1287,)\n"
     ]
    }
   ],
   "source": [
    "#print(gen_id[0])\n",
    "print(len(gen_id))\n",
    "print(len(gen_id)/2)\n",
    "\n",
    "half = int(len(gen_id)/2)\n",
    "\n",
    "# data\n",
    "x_val = gen_id[:half]\n",
    "partial_x_train = gen_id[half:]\n",
    "\n",
    "# labels of data\n",
    "y_val = Z_ee_jet[:half]\n",
    "partial_y_train = Z_ee_jet[half:]\n",
    "\n",
    "print(x_val)\n",
    "print(partial_x_train)\n",
    "print(len(x_val))\n",
    "print(len(partial_x_train))\n",
    "print(len(gen_id[0]))\n",
    "print(len(x_val[0]))\n",
    "print(len(partial_x_train[0]))\n",
    "print(x_val.shape)\n",
    "print(partial_x_train.shape)\n",
    "print(y_val)\n",
    "print(partial_y_train)\n",
    "print(y_val.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Still need to figure out maxlen) -- Done(-ish)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Possible error meanign for below block, re: array vs seq~~: https://www.google.com/search?client=ubuntu&channel=fs&q=setting+an+array+element+with+a+sequence.&ie=utf-8&oe=utf-8 -- **Resolved [x]**: (for model.fit, x is data and y is labels) https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1287 samples, validate on 1287 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[88,12] = -2 is not in [0, 2575)\n\t [[{{node embedding/embedding_lookup}} = ResourceGather[Tindices=DT_INT32, _class=[\"loc:@training/Adam/gradients/embedding/embedding_lookup_grad/Reshape\"], dtype=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding/embeddings, embedding/Cast)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e1e02f969762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[88,12] = -2 is not in [0, 2575)\n\t [[{{node embedding/embedding_lookup}} = ResourceGather[Tindices=DT_INT32, _class=[\"loc:@training/Adam/gradients/embedding/embedding_lookup_grad/Reshape\"], dtype=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding/embeddings, embedding/Cast)]]"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
